# 4. 開発ワークフロー

このドキュメントでは、標準アーキテクチャに基づいたモデル開発の推奨ワークフローを解説します。ワークフローは大きく2つのフェーズに分かれます。

1.  **フェーズ1: コア機能の実装**: まずは標準構成に基づき、モデルが学習できる最小限の状態（Minimum Viable Model）を構築します。
2.  **フェーズ2: 機能拡張と反復改善**: コア機能が動作することを確認した後、必要な機能を段階的に追加し、実験を通じてモデルの精度を向上させます。

---

## 4.1. フェーズ1: コア機能の実装

このフェーズの目標は、**「とにかく一度、学習ループを最後まで回すこと」**です。最初から完璧を目指さず、シンプルな設定で素早くプロトタイプを完成させましょう。

1.  **目的定義とディレクトリ作成**

    - **目的の明確化**: このモデルの「入力」と「出力」は何かを定義します。
    - **ディレクトリ作成**: `development/`以下に、`01_directory_structure.md`で定義された**標準構成**のディレクトリ群を作成します。

2.  **設定ファイルの準備 (`configs/`)**

    - `configs/config.yaml`を作成し、`data`, `model`, `training`, `callbacks`の`defaults`を定義します。
    - 各モジュールのディレクトリに、ごくシンプルな設定ファイル（例: `default.yaml`）を配置します。
    - 特に`configs/callbacks/default.yaml`には、少なくともモデルを保存するための`ModelCheckpoint`の設定を記述しておきましょう。

3.  **データパイプラインの実装 (`training/`)**

    - `training/dataset.py`: データセットから1つのサンプル（画像とラベルなど）を正しく取得できる`__getitem__`を実装します。
    - `training/datamodule.py`: `dataset.py`を使い、学習・検証用の`DataLoader`を準備します。

4.  **モデルと学習ロジックの実装**

    - `model/`: `nn.Module`として、ごく単純なモデルアーキテクチャを定義します。
    - `training/module.py`: `LightningModule`を実装します。モデル、単純な損失関数（例: `nn.MSELoss`）、基本的なオプティマイザ（例: `torch.optim.Adam`）をインスタンス化し、`training_step`を定義します。

5.  **エントリーポイントとコールバックの作成 (`main.py`, `runner/`, `callbacks/`)**
    - `callbacks/`: `cfg.callbacks`を解析し、`ModelCheckpoint`などのコールバックインスタンスのリストを返すファクトリ関数（例: `build_callbacks(cfg)`）を実装します。
    - `runner/train.py`: `build_callbacks`を呼び出してコールバックのリストを取得し、`DataModule`や`LightningModule`と共に`Trainer`に渡して`fit()`を呼び出すロジックを実装します。
    - `main.py`: `@hydra.main`デコレータを使い、`runner`を呼び出すエントリーポイントを作成します。

---

## 4.2. フェーズ2: 機能拡張と反復改善

コア機能が安定して動作するようになったら、モデルの性能を向上させるための機能拡張と実験サイクルを開始します。

1.  **機能の拡張**

    - **テストの追加 (`tests/`)**: データ処理やモデルのフォワードパスなど、重要な部分の単体テストを作成し、コードの信頼性を高めます。
    - **カスタム機能の実装**: 必要に応じて、以下のディレクトリを作成し、機能を分離・実装します。
      - `losses/`: より複雑な、あるいはタスクに特化した損失関数。
      - `callbacks/`: 学習の途中経過の可視化や、特定の条件でのモデル保存など。
      - `utils/`: プロジェクト全体で利用する共通ヘルパー関数。

2.  **実験と改善サイクル**
    - **仮説立案**: モデルの性能を改善するための仮説を立てます（例: 「学習率を下げれば精度が上がるのではないか？」）。
    - **実験の準備**: 仮説を検証するために、`configs/`以下のYAMLファイルを変更、またはコマンドライン引数で設定を上書きします。
      ```bash
      # 学習率とバッチサイズを変更して実験
      python main.py training.optimizer.lr=1e-5 data.batch_size=32
      ```
    - **結果の分析**: Hydraが出力するログや、`analysis/`に作成したスクリプトを用いて実験結果を評価します。
    - **反復**: 分析結果をもとに新たな仮説を立て、このサイクルを繰り返します。
