### 汎用モデル開発アーキテクチャ

このアーキテクチャの核心は、**「関心の分離」**と**「設定ファイル駆動」**です。コードの再利用性を高め、誰が開発しても一貫性のある構造を維持することを目的とします。

#### 1. 基本的なディレクトリ構成

新しいモデル開発プロジェクト（例：`development/court_pose/vit_heatmap`）は、必ず以下の構造に従います。

```
<project_root>/
├── configs/         # 実験設定 (Hydra)
├── model/           # モデル定義 (PyTorch nn.Module)
├── training/        # 学習関連 (Lightning)
│   ├── lit_module.py  # 学習ロジック (損失、最適化)
│   ├── datamodule.py  # データ供給の管理
│   ├── dataset.py     # データセット本体
│   └── transforms.py  # データ拡張
├── runner/          # 実行担当
│   ├── train.py       # 学習タスクの実行
│   └── infer.py       # 推論タスクの実行
├── analysis/        # 推論結果の解析・後処理
├── callbacks/       # 学習中のフック (ログ出力など)
├── utils/           # 共通ヘルパー・ツール
└── main.py          # 全体のエントリーポイント
```

#### 2. 各コンポーネントの役割

| コンポーネント               | 役割             | 説明                                                                                                                                                                      |
| :--------------------------- | :--------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **`main.py`**                | **司令塔**       | `hydra`と連携し、設定を読み込んで `train` や `infer` などのタスクを `runner` に振り分ける唯一の入口。                                                                     |
| **`configs/`**               | **実験設定**     | 学習率、バッチサイズ、ファイルパスなど、**コードから分離された全てのパラメータ**をYAMLファイルで管理。これにより、コードを変更せず様々な実験を再現可能にします。          |
| **`runner/`**                | **タスク実行役** | `TrainRunner`や`InferRunner`が、設定に基づいてモデルやデータモジュールを初期化し、`pytorch-lightning`の`Trainer`を起動するなど、具体的なタスクの実行フローを管理します。  |
| **`training/lit_module.py`** | **学習の心臓部** | `pytorch-lightning`の`LightningModule`を継承。モデル(`nn.Module`)を内包し、**損失関数の定義、オプティマイザの設定、学習・検証ステップのロジック**をここに集約します。     |
| **`training/datamodule.py`** | **データ供給役** | `LightningDataModule`を継承。`dataset.py`を使い、学習・検証・テスト用の**データ分割**と**データローダーの作成**を担当します。データの準備に関する責務をここにまとめます。 |
| **`training/dataset.py`**    | **データ変換役** | `torch.utils.data.Dataset`を継承。ディスクから画像やラベルを1つずつ読み込み、モデルが扱える形式（例：テンソル、ヒートマップ）に変換する役割を担います。                   |
| **`training/transforms.py`** | **データ拡張役** | `albumentations`などを使い、学習時のデータ拡張（回転、反転など）と、検証・テスト時の前処理（リサイズ、正規化）を定義します。                                              |
| **`model/`**                 | **モデル定義**   | 純粋な`torch.nn.Module`として、ニューラルネットワークのアーキテクチャのみを定義します。この部分は`pytorch-lightning`に依存せず、再利用可能です。                          |
| **`analysis/` / `tracker/`** | **後処理役**     | 推論時に、モデルの生の出力（例：ヒートマップ）を、より意味のある情報（例：座標、追跡軌道）に変換するモジュールです。                                                      |
| **`callbacks/`**             | **補助役**       | `pytorch-lightning`の学習ループにフックし、学習途中の画像ログをTensorBoardに保存したり、モデルのチェックポイントを管理したりする再利用可能な部品です。                    |
| **`utils/`**                 | **道具箱**       | チェックポイントの重み変換ツールなど、プロジェクト固有だが他のコンポーネントに分類できない便利なスクリプトや関数を格納します。                                            |

#### 3. 開発ワークフロー

新しいモデルを開発する際は、以下のステップに従います。

1.  **目的定義**: 何を入力とし、何を出力とするかを明確にする。
2.  **設定ファイル作成 (`configs/`)**: プロジェクトのベースとなる設定（ファイルパス、モデルの基本パラメータ等）をYAMLに記述する。
3.  **データ準備 (`training/dataset.py`, `transforms.py`)**:
    1.  `dataset.py`で、1サンプル分のデータ（例：画像とラベル）を読み込み、正解データ（例：ヒートマップ）を生成するクラスを作成する。
    2.  `transforms.py`で、データ拡張と正規化の処理を定義する。
4.  **データ供給 (`training/datamodule.py`)**: `DataModule`を作成し、データセットの分割とデータローダーの準備を実装する。
5.  **モデル定義 (`model/`)**: `nn.Module`としてネットワークアーキテクチャを実装する。
6.  **学習ロジック実装 (`training/lit_module.py`)**: `LightningModule`を作成し、モデル、損失関数、オプティマイザを組み合わせて学習サイクルを定義する。
7.  **実行 (`main.py`, `runner/`)**:
    1.  `TrainRunner`が`DataModule`と`LightningModule`をインスタンス化し、学習を開始するように実装する。
    2.  `main.py`から`hydra`経由で`TrainRunner`を呼び出す。
8.  **推論実装**: 学習完了後、`InferRunner`と`analysis`モジュールを実装し、新しいデータに対する推論パイプラインを構築する。

---

このテンプレートに従うことで、プロジェクトの見通しが良くなり、コンポーネントの再利用が促進され、開発効率が大幅に向上します。今後の全ての開発において、このアーキテクチャを基盤としてください。
