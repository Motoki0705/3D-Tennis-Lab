defaults:
  - data: seq
  - losses: weights
  - semisup: selftrain
  - gan: none
  - tracker: none
  - physics: ballistics
  - _self_

seed: 42

model:
  backbone:
    embed_dim: 96
    depths: [2, 2, 6, 2]
    num_heads: [3, 6, 12, 24]
    window_size: 7
    drop_path_rate: 0.1
    moe:
      enabled: false
      stages: [16, 32]
      num_experts: 4
  temporal_encoder:
    enabled: true
    strides: [8, 16, 32]
  temporal:
    enabled: true
  deep_supervision_strides: [8, 16, 32]
  decoder_channels: [256, 128, 64]
  heatmap_channels: 1
  heads:
    hidden: 256

data:
  images_root: data/processed/ball/images
  labeled_json: data/processed/ball/annotation.json
  unlabeled_json: data/processed/ball/non_annotation.json
  img_size: [320, 640] # H, W
  T: 9
  frame_stride: 1
  scales: [8, 16, 32]
  sigma_px: [2.0, 3.0, 4.0]
  supervise_hm_on_v1: false
  batch_size: 4
  num_workers: 4
  pin_memory: true
  drop_last: true
  shuffle: true
  val_split: 0.1

streams:
  unlabeled_ratio: 1.0

semisup:
  name: selftrain
  enable: false
  teacher: frozen
  teacher_ckpt: checkpoints/supervised_student.ckpt
  pseudo:
    target: soft
    q_weights: { peak: 0.5, entropy: 0.2, physics: 0.3, disc: 0.0 }
    tau_start: 0.3
    tau_end: 0.7
    warmup_epochs: 10
  consistency_weight: 0.0

gan:
  enable: false
  d_steps: 5
  lambda_gp: 10.0
  lambda_adv: 0.05

tracker:
  fuse: false
  kalman:
    q_pos: 1.0
    q_vel: 0.1
    r_det: 2.0

opt:
  lr_backbone: 1e-4
  lr_heads: 5e-4
  wd: 0.05

trainer:
  _target_: pytorch_lightning.Trainer
  max_epochs: 80
  precision: 16-mixed
  accelerator: auto
  devices: 1
  log_every_n_steps: 10
  enable_checkpointing: true
  gradient_clip_val: 0.0
